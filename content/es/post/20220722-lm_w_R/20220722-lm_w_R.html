---
title: "Regresión Lineal en R"
description: "Análisis del precio de la vivienda en R con {car}, {caret}, & {MuMIn}"
summary: "En este post vamos a hablar de la regresión lineal, un tipo de modelo lineal que se ha utilizado durante mucho tiempo. Es una herramienta muy útil para el aprendizaje estadístico, y su comprensión se hace necesaria para entender otros métodos de modelamiento más complejos. En este artículo vamos a utilizar las regresiones lineales para explorar las predicciones de los precios de la vivienda en los Estados Unidos, mientras entendemos sus componentes y cómo calcularlos en R."
author: "Javier Tamayo-Leiva" 
date: 2022-07-22
featured_image: "/images/post/20220722-lm_w_R/20220722-lm_w_R_wide.png"
layout: post
toc: FALSE
tags: ["DataViz", "Statistics", "stat", "Regression", "Linear model", "Machine Learning"]
output: distill::distill_article
draft: true
---

<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>
<script src="/rmarkdown-libs/htmlwidgets/htmlwidgets.js"></script>
<link href="/rmarkdown-libs/datatables-css/datatables-crosstalk.css" rel="stylesheet" />
<script src="/rmarkdown-libs/datatables-binding/datatables.js"></script>
<script src="/rmarkdown-libs/jquery/jquery-3.6.0.min.js"></script>
<link href="/rmarkdown-libs/dt-core/css/jquery.dataTables.min.css" rel="stylesheet" />
<link href="/rmarkdown-libs/dt-core/css/jquery.dataTables.extra.css" rel="stylesheet" />
<script src="/rmarkdown-libs/dt-core/js/jquery.dataTables.min.js"></script>
<link href="/rmarkdown-libs/crosstalk/css/crosstalk.min.css" rel="stylesheet" />
<script src="/rmarkdown-libs/crosstalk/js/crosstalk.min.js"></script>


<div id="table-of-content" class="section level4">
<h4>Table of Content</h4>
<ul>
<li><a href="#intro">Introducción</a></li>
<li><a href="#body1">Regresión Lineal</a></li>
<li><a href="#body2">Regresión Lineal Simple</a></li>
</ul>
<hr />
</div>
<div id="intro" class="section level2">
<h2>Introducción</h2>
<p>La ventaja del <strong>modelamiento matemático</strong> o de la creación de un <strong>modelo matemático</strong> -en adelante simplemente modelización y modelización- sobre la estadística descriptiva más simple es que los modelos nos permiten predecir valores futuros de una variable cuantitativa o cualitativa de interés. Pero no te asustes por el término <strong>modelo</strong>, porque en matemáticas el término puede aplicarse para describir una <strong>ecuación</strong> o <strong>función</strong> que nos permite entender el comportamiento de una <strong>variable de respuesta</strong> como resultado de una o múltiples <strong>variables explicativas</strong>. Existen muchos tipos de algoritmos de construcción de modelos, pero en este post hablaremos de la <strong>Regresión Lineal</strong> un método que pertenece a los <strong>Modelos Lineales</strong> y que se puede clasificar como <strong>Aprendizaje Supervisado</strong><a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a>. La Regresión Lineal ha sido utilizada durante mucho tiempo, pero sigue siendo extremadamente útil para el <strong>Aprendizaje Estadístico</strong><a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a>, y se hace necesario entender otros métodos de modelado más complejos -que son más flexibles pero menos interpretables-. Además, debido a sus propiedades los coeficientes del modelo pueden ser interpretados más fácilmente que los de otros modelos, permitiéndonos entender mejor el comportamiento de la respuesta directamente desde el modelo, como descubriremos a lo largo de este artículo.<br></p>
</div>
<div id="body1" class="section level2">
<h2>Regresión Lineal</h2>
<p>Como se ha mencionado anteriormente la Regresión Lineal es un Modelo Lineal, y se utiliza para predecir el valor de una variable continua a menudo llamada Variable de Respuesta, basándose en su relación lineal con una o más Variables Explicativas. Así, este tipo de modelos que asumen la relación lineal entre la respuesta y la variable explicativa se denominan Modelos Lineales, y son un tipo dentro de los Modelos Lineales Generalizados o <strong>GLM</strong>, donde para los Modelos Lineales también se asume la distribución normal -Gaussiana- de los residuos.<br></p>
<p>Matemáticamente, la relación lineal entre la variable de respuesta y la variable explicativa que supone la regresión lineal puede escribirse como sigue:<br><br></p>
<p><span class="math display">\[{Y = \beta_0 + \beta_1 * X} \]</span>
<br>
Donde:</p>
<ul>
<li><p><span class="math inline">\(Y\)</span> = <strong>Variable de respuesta</strong> (también denominada <strong>variable dependiente</strong>).</p>
<p>La variable que se desea predecir.</p></li>
<li><p><span class="math inline">\(X\)</span> = <strong>Variables explicativas</strong> (también denominadas <strong>variables independientes</strong>).</p>
<p>Variables que explican cómo se comportará la variable de respuesta.</p></li>
<li><p><span class="math inline">\({\beta_0}\)</span> = <strong>Intercepto</strong></p>
<p>Constante desconocida que representa el valor de Y cuando X es cero.</p></li>
<li><p><span class="math inline">\({\beta_1}\)</span> = <strong>Pendiente</strong></p>
<p>Constante desconocida que representa el valor en el que cambia Y por cada unidad X.<br><br></p></li>
</ul>
<p>El objetivo de los modelos de regresión lineal es siempre ajustar una línea recta lo más cercana posible a los datos analizados. Las rectas generadas se definen, por tanto, por la combinación de los dos términos desconocidos, el intercepto y la pendiente, con la variable explicativa. Estos dos términos que se calculan a partir de los datos analizados también se conocen como los coeficientes o parámetros del modelo. Entonces ahora que sabemos como interpretar la ecuación podemos simplificar la terminología de la siguiente forma:<br><br></p>
<p><span class="math display">\[{Respuesta = intercepto + pendiente * Explicativa} \]</span>
<br>
Ahora que entendemos el modelo básico de regresión lineal, vamos a calcular algunos coeficientes con nuestro conjunto de datos de hoy sobre el precio de la vivienda en Estados Unidos. Para ello, primero tenemos que echar un vistazo a la estructura de los datos. Nuestro conjunto de datos tiene 5.000 observaciones y 8 variables, con información sobre la renta media de la zona, la edad media de la zona para las viviendas, el número de habitaciones de la casa, los dormitorios, los no dormitorios, la población de la zona, el precio de la vivienda y su dirección. Una vez examinada la tabla de la muestra, calcularemos una regresión lineal simple para empezar. <br><br></p>
<div id="htmlwidget-1" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-1">{"x":{"filter":"none","vertical":false,"fillContainer":true,"data":[["1","2","3","4","5","6","7","8","9","10","11","12","13","14","15","16","17","18","19","20","21","22","23","24","25","26","27","28","29","30"],[79545.4585743168,79248.6424548257,61287.0671786568,63345.240046228,59982.197225708,80175.7541594853,64698.4634278877,78394.3392775308,59927.6608133496,81885.9271840957,80527.4720829229,50593.6954970428,39033.8092369824,73163.6634410467,69391.3801843616,73091.8667458232,79706.9630576574,61929.0770180893,63508.19429943,62085.2764034049,86294.9990887106,60835.089978854,64490.6502667551,60697.3515394483,59748.8554869742,56974.4765387964,82173.626075846,64626.8809781355,90499.0574513475,59323.7920997004],[5.68286132161559,6.00289980827524,5.86588984031,7.18823609451864,5.04055452310628,4.98840775753371,6.02533590688715,6.98977974771828,5.36212556960358,4.42367178989788,8.09351268063935,4.49651279309704,7.67175537285443,6.91953482545656,5.34477617673573,5.44315646653547,5.06788959105897,4.78855024180589,5.94716513955247,5.73941084363057,6.62745693978174,5.55122159199033,4.21032287005484,6.1704840908385,5.3393398807459,8.28756219375901,4.01852468494281,5.4433595901921,6.3843589207152,6.97782794017884],[7.00918814279224,6.73082101909492,8.5127274303751,5.58672866482765,7.83938778512049,6.10451243942888,8.14775958502343,6.62047799518503,6.3931209805509,8.16768800347235,5.04274679964598,7.46762740400802,7.2500293172735,5.99318790094557,8.40641771453425,8.51751271113798,8.21977112328626,5.09700955437756,7.18777383532973,7.09180810424997,8.01189785315056,6.51717503809478,5.47808773076914,7.15053657233596,7.7486816056066,7.31287997146301,6.99269875679184,6.98875353866204,4.24219130157263,8.2736970777766],[4.09,3.09,5.13,3.26,4.23,4.04,3.41,2.42,2.3,6.1,4.1,4.49,3.1,2.27,4.37,4.01,3.12,4.3,5.12,5.49,4.07,2.1,4.31,6.34,4.23,4.33,2.03,4,3.04,4.07],[2.91918814279224,3.64082101909492,3.3827274303751,2.32672866482765,3.60938778512049,2.06451243942888,4.73775958502343,4.20047799518503,4.0931209805509,2.06768800347235,0.942746799645982,2.97762740400802,4.15002931727349,3.72318790094557,4.03641771453425,4.50751271113798,5.09977112328626,0.797009554377562,2.06777383532973,1.60180810424997,3.94189785315056,4.41717503809478,1.16808773076914,0.810536572335959,3.5186816056066,2.98287997146301,4.96269875679184,2.98875353866204,1.20219130157263,4.2036970777766],[23086.8005026865,40173.0721736448,36882.1593997046,34310.2428309071,26354.1094721031,26748.4284246897,60828.2490854072,36516.3589724938,29387.3960028159,40149.9657492134,47224.3598402219,34343.9918855788,39220.3614673725,32326.1231394881,35521.2940331732,23929.524053268,39717.8135763095,24595.901497823,35719.6530520309,44922.1067022931,47560.7753362952,45574.7416622579,40358.9601056176,28140.9670877248,27809.9865437589,40694.8695130223,38853.9180664817,27784.7422801859,33970.1649903713,37520.6577324497],[1059033.55787012,1505890.91484695,1058987.98787608,1260616.80662945,630943.48933854,1068138.07439353,1502055.81737441,1573936.56447772,798869.532833163,1545154.81264196,1707045.72215806,663732.396896327,1042814.09782009,1291331.51848582,1402818.21016585,1306674.6599512,1556786.60019477,528485.246730596,1019425.93675783,1030591.42921161,2146925.33988866,929247.5995364,718887.231500928,743999.819160197,895737.133383508,1453974.50595087,1125692.50729529,975429.492792922,1240763.76557148,1577017.76000155],["208 Michael Ferry Apt. 674\nLaurabury, NE 37010-5101","188 Johnson Views Suite 079\nLake Kathleen, CA 48958","9127 Elizabeth Stravenue\nDanieltown, WI 06482-3489","USS Barnett\nFPO AP 44820","USNS Raymond\nFPO AE 09386","06039 Jennifer Islands Apt. 443\nTracyport, KS 16077","4759 Daniel Shoals Suite 442\nNguyenburgh, CO 20247","972 Joyce Viaduct\nLake William, TN 17778-6483","USS Gilbert\nFPO AA 20957","Unit 9446 Box 0958\nDPO AE 97025","6368 John Motorway Suite 700\nJanetbury, NM 26854","911 Castillo Park Apt. 717\nDavisborough, PW 78603","209 Natasha Stream Suite 961\nHuffmanland, NE 52457","829 Welch Track Apt. 992\nNorth John, AR 26532-5136","PSC 5330, Box 4420\nAPO AP 08302","2278 Shannon View\nNorth Carriemouth, NM 84617","064 Hayley Unions\nNicholsborough, HI 44161-1887","5498 Rachel Locks\nNew Gregoryshire, PW 54755","Unit 7424 Box 2786\nDPO AE 71255","19696 Benjamin Cape\nStephentown, ME 36952-4733","030 Larry Park Suite 665\nThomashaven, HI 87941-5197","USNS Brown\nFPO AP 85833","95198 Ortiz Key\nPort Sara, TN 24541-2855","9003 Jay Plains Suite 838\nLake Elizabeth, IN 90622-0804","24282 Paul Valley\nWest Perry, MI 03169-5806","61938 Brady Falls\nLewisfort, DE 61227","3599 Ramirez Springs\nJacksonhaven, AZ 72798","073 Christopher Falls Suite 882\nWest Cynthia, MA 89075-2814","6531 Chase Prairie Apt. 245\nSusanshire, MN 22365","17124 Johnson Squares\nLake Robertfurt, AL 61811-3832"]],"container":"<table class=\"display fill-container\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>Income<\/th>\n      <th>House_Age<\/th>\n      <th>N_Rooms<\/th>\n      <th>N_Bedrooms<\/th>\n      <th>N_no_Bedrooms<\/th>\n      <th>Area_Population<\/th>\n      <th>Price<\/th>\n      <th>Address<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"pageLength":10,"scrollY":"400px","columnDefs":[{"className":"dt-right","targets":[1,2,3,4,5,6,7]},{"orderable":false,"targets":0}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<p><br></p>
</div>
<div id="body2" class="section level2">
<h2>Regresión Lineal Simple</h2>
<p>Como su nombre indica claramente, la <strong>Regresión Lineal Simple</strong> busca un modelo sencillo en el que la variable de respuesta esté asociada a una única variable explicativa. Y en el que se supone una relación casi lineal entre estos dos componentes. Así, el primer paso es definir la variable que queremos predecir o entender con nuestro modelo. Si revisamos el conjunto de datos identificaríamos una posible variable de interés: El precio de la vivienda, que es la columna denominada <code>Price</code>. Pero, ¿cómo vamos a decidir qué otras variables son las mejores candidatas para ser incluidas en nuestro modelo? Bien, aquí podemos utilizar dos enfoques. El primero es asignar una hipótesis basada en alguna información previa, como que las casas en los barrios de altos ingresos serán más caras, o que las casas con más habitaciones serán más caras que las casas con menos habitaciones. Luego podemos crear modelos con estas variables y comparar los resultados para encontrar el mejor ajuste. Pero este enfoque puede hacer que pasemos por alto alguna característica interesante de nuestros datos. Así que otro enfoque es dejar que los datos nos digan qué factor parece estar más relacionado con nuestra variable de respuesta. Una forma de hacerlo es buscar tendencias lineales entre nuestra respuesta y cada predictor. Podemos hacerlo trazando cada variable frente a <code>Price</code>, o analizando la correlación lineal entre las variables con una correlación de Pearson, que mide la fuerza de una relación lineal entre pares.</p>
<p><br><br><br></p>
<details>
<summary style="font-size:10pt;">
R Session Info
</summary>
<pre><code>## R version 4.1.3 (2022-03-10)
## Platform: x86_64-apple-darwin17.0 (64-bit)
## Running under: macOS Big Sur/Monterey 10.16
## 
## Matrix products: default
## BLAS:   /Library/Frameworks/R.framework/Versions/4.1/Resources/lib/libRblas.0.dylib
## LAPACK: /Library/Frameworks/R.framework/Versions/4.1/Resources/lib/libRlapack.dylib
## 
## locale:
## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
##  [1] caret_6.0-92     lattice_0.20-45  metrica_2.0.0    modelr_0.1.8    
##  [5] ggfortify_0.4.14 MuMIn_1.46.0     broom_0.7.12     car_3.0-12      
##  [9] carData_3.0-5    cowplot_1.1.1    corrplot_0.92    forcats_0.5.1   
## [13] stringr_1.4.0    dplyr_1.0.9      purrr_0.3.4      readr_2.1.2     
## [17] tidyr_1.2.0      tibble_3.1.7     ggplot2_3.3.6    tidyverse_1.3.1 
## 
## loaded via a namespace (and not attached):
##   [1] colorspace_2.0-3     ellipsis_0.3.2       class_7.3-20        
##   [4] fs_1.5.2             rstudioapi_0.13      listenv_0.8.0       
##   [7] DT_0.23              gsl_2.1-7.1          bit64_4.0.5         
##  [10] prodlim_2019.11.13   fansi_1.0.3          lubridate_1.8.0     
##  [13] xml2_1.3.3           codetools_0.2-18     splines_4.1.3       
##  [16] cachem_1.0.6         knitr_1.37           jsonlite_1.8.0      
##  [19] pROC_1.18.0          dbplyr_2.1.1         compiler_4.1.3      
##  [22] httr_1.4.3           backports_1.4.1      assertthat_0.2.1    
##  [25] Matrix_1.4-0         fastmap_1.1.0        cli_3.3.0           
##  [28] htmltools_0.5.2      tools_4.1.3          gtable_0.3.0        
##  [31] glue_1.6.2           reshape2_1.4.4       Rcpp_1.0.8.3        
##  [34] cellranger_1.1.0     jquerylib_0.1.4      vctrs_0.4.1         
##  [37] nlme_3.1-155         blogdown_1.8         crosstalk_1.2.0     
##  [40] iterators_1.0.14     timeDate_3043.102    xfun_0.29           
##  [43] gower_1.0.0          globals_0.14.0       rvest_1.0.2         
##  [46] lifecycle_1.0.1      future_1.23.0        MASS_7.3-55         
##  [49] scales_1.2.0         ipred_0.9-12         vroom_1.5.7         
##  [52] hms_1.1.1            parallel_4.1.3       curl_4.3.2          
##  [55] yaml_2.3.5           memoise_2.0.1        gridExtra_2.3       
##  [58] sass_0.4.1           rpart_4.1.16         stringi_1.7.6       
##  [61] RSQLite_2.2.10       foreach_1.5.2        minerva_1.5.10      
##  [64] energy_1.7-10        boot_1.3-28          lava_1.6.10         
##  [67] rlang_1.0.2          pkgconfig_2.0.3      evaluate_0.14       
##  [70] htmlwidgets_1.5.4    recipes_0.1.17       bit_4.0.4           
##  [73] tidyselect_1.1.2     parallelly_1.30.0    plyr_1.8.7          
##  [76] magrittr_2.0.3       bookdown_0.24        R6_2.5.1            
##  [79] generics_0.1.2       DBI_1.1.2            pillar_1.7.0        
##  [82] haven_2.4.3          withr_2.5.0          survival_3.2-13     
##  [85] abind_1.4-5          nnet_7.3-17          future.apply_1.8.1  
##  [88] crayon_1.5.1         utf8_1.2.2           tzdb_0.3.0          
##  [91] rmarkdown_2.11       grid_4.1.3           readxl_1.3.1        
##  [94] data.table_1.14.2    blob_1.2.2           ModelMetrics_1.2.2.2
##  [97] reprex_2.0.1         digest_0.6.29        stats4_4.1.3        
## [100] munsell_0.5.0        bslib_0.3.1</code></pre>
</details>
<p><br></p>
<p style="font-size:10pt;">
Notas
</p>
</div>
<div class="footnotes footnotes-end-of-document">
<hr />
<ol>
<li id="fn1"><p>El <strong>Aprendizaje Supervisado</strong> se refiere a los métodos en los que se requiere para cada observación de una medida de la variable explicatoria, una medida de la variable de respuesta. Esta característica nos permitirá crear y luego comparar los valores predichos de nuestro modelo frente a la respuesta real de la variable.<a href="#fnref1" class="footnote-back">↩︎</a></p></li>
<li id="fn2"><p>El <strong>Aprendizaje Estadístico</strong> se refiere a una gran cantidad de herramientas que pueden utilizarse para comprender mejor los datos.<a href="#fnref2" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
